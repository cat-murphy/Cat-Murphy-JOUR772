---
title: "lab_12"
author: "Mitchell Hang"
date: "2023-05-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## You will need

-   tidytext and our usual libraries

## Load libraries and establish settings

**Task** Create a codeblock and load appropriate packages and settings for this lab.

```{r}
# Turn off scientific notation
options(scipen=999)

# Load the tidyverse.
library(tidytext)
library(tidyverse)
library(dplyr)
library(janitor)
library(lubridate)
library(rvest)
```

## Questions

##### **Q1.** You've been assigned to report a story about the leading reasons that Maryland attorneys get sanctioned by the state for misconduct. The state [publishes lists of sanctions](https://www.courts.state.md.us/attygrievance/sanctions) that contain a short text description about the situation. Load the CSV file in the data folder containing records from fiscal year 2011 onwards. Make a list of unique words from the text column, then following the example in the pre_lab, remove common "stop words" from that list and create a list of the top 10 words containing the percentage of occurrences each word represents. What's the leading word in that answer and, broadly, what do you think the top 10 words describe?

```{r}
#Load the data
md_attorney_sanctions <- read_csv("data/md_attorney_sanctions.csv")
```

```{r}
#Create list of unique words
uniques <- md_attorney_sanctions |> 
  select(text) |>
  unnest_tokens(word, text)

view(uniques)

uniques |>
  count(word, sort = TRUE) |>
  top_n(25) |>
  mutate(word = reorder(word, n)) |>
  ggplot(aes(x = word, y = n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
      labs(x = "unique words",
      y = "count",
      title = "Count of unique words found in Maryland attorney sanctions")
```

```{r}
#Load stop words
data("stop_words")

stop_words <- stop_words |> 
  add_row(word = "to") |> 
  add_row(word = "the") |> 
  add_row(word = "for") |>
  add_row(word = "and") |>
  add_row(word = "of") |>
  add_row(word = 'in') |> 
  add_row(word = 'a') |> 
  add_row(word = 'on') |> 
  add_row(word = 'with') |> 
  add_row(word = "by") |> 
  add_row(word = "an") |> 
  add_row(word = "his") |> 
  add_row(word = "her") |>
  add_row(word = "attorney") |> 
  add_row(word = "client") |> 
  add_row(word = "clients") |>
  add_row(word = "representation") |>
  add_row(word = "respondent") |>
  add_row(word = "conduct")
```

```{r}
#Remove stop words from unique words list
uniques |>
  anti_join(stop_words) |>
  group_by(word) |>
  tally(sort=TRUE) |>
  mutate(percent = (n/sum(n))*100) |>
  top_n(10)
```

**A1.** Excluding general stop words like "the" and topical stop words like "attorney," the most prevalent word is "failing." Not only does the word "failing" appear more than any other word, it appears 2 1/2 times more than the next most common word. The word is used 1,571 times — more than once per sanction — and accounts for roughly 5% of all meaningful words. (And this doesn't even include the word "failed," which is also in the top 10.) The top 10 words, though, tell a broader story about the kind of misconduct attorneys are often sanctioned for. For example, the repetition of the words "funds," "trust" and "account" tells me that many attorneys are being sanctioned for misconduct involving money — actions like taking advantage of clients or stealing money. And words like "reprimand," "disbarred" and "suspension" illustrate the spectrum of punishments being handed down.

------------------------------------------------------------------------

##### **Q2.** Let's move beyond single words to phrases. Make a list of the top 10 three-word phrases, called trigrams, based on the example from the pre_lab (you'll need to modify the example code to do this). What's the top trigram and how often does it appear? What does that phrase mean in legal terms?

```{r}
# Check the task 12 on Pre-lab 11 to see if you can use that code
attorney_sanctions_trigrams <- md_attorney_sanctions |>
  unnest_tokens(trigram, text, token = "ngrams", n = 3) |>
  separate(trigram, c("word1", "word2", "word3"), sep = " ") |>
  filter(!word1 %in% stop_words$word) |>
  filter(!word2 %in% stop_words$word) |>
  filter(!word3 %in% stop_words$word) |>
  mutate(trigram = paste(word1, word2, word3, sep=" ")) |>
  group_by(trigram) |>
  tally(sort=TRUE) |>
  mutate(percent = (n/sum(n))*100) |>
  top_n(10)
```

**A2.** The top trigram in the sanction text is "conduct involving dishonesty," appearing a total of 155 times. In legal terminology, the phrase refers to things like violating the rules of professional conduct, committing a crime that impacts an attorney's trustworthiness or interfering with the administration of justice. This would suggest that many of the sanctioned attorneys, regardless of their specific brand of misconduct, are ultimately accused of violating their clients' trust in one way or another.

------------------------------------------------------------------------

##### **Q3.** Let's drop back down to more traditional text analysis - take the top trigram from Q2 and write code to see how many times it occurs in the text column in each fiscal year. What do you think the answer produced by your code suggests? What else could you do to try and clarify the most important reasons attorneys get sanctioned?

```{r}
md_attorney_sanctions |>
  filter(str_detect(text, "conduct involving dishonesty")) |>
  group_by(fiscal_year) |>
  summarise(count=n()) |>
  arrange(desc(count))
```

**A3.** The year-by-year breakdown identifies a *fascinating* trend in the use of the phrase "conduct involving dishonesty" over time. Clearly, the prevalence of the phrase in attorney sanctions increased dramatically in the late 2010s. Case in point, between 2019 and 2022, the term appeared in sanctions more than 25 times per year. Keep in mind that it had never before appeared even half this many times in a single year. Weirdly, though, this dropped off a cliff in 2023, when the phrase only appeared twice. I don't really know how to explain this spike, but it definitely is interesting. It seems like the pandemic could explain some of the increase, but it wouldn't account for the 2019 figure. In any case, while the trigram method of text analysis is certainly insightful, I think it would helpful to group the sanctions using `str_detect`. Because many of the legal phrases — like "conduct involving dishonesty" — are so broad in scope, grouping the sanctions by specific terms would allow us to drill down which sanctions pertain to money, criminal activity, conflicts of interest, breaking confidentiality, etc.
